# language: vi

# pipeline:
#    - name: HFTransformersNLP # thay cho WhitespaceTokenizer
#    model_weight: "bert-base-uncased"
#    model_name: "bert"
#    - name: LanguageModelTokenizer
#    - name: LanguageModelFeaturizer
#    - name: CountVectorsFeaturizer
#      analyzer: char_wb
#      min_ngram: 1
#      max_ngram: 4
#    - name: DIETClassifier
#      epochs: 100
#      constrain_similarities: true
#    - name: ResponseSelector
#      epochs: 100
#      constrain_similarities: true
#    - name: FallbackClassifier
#      threshold: 0.6
#      ambiguity_threshold: 0.1
   

# policies:
#   - name: MemoizationPolicy
#   - name: RulePolicy
#   - name: UnexpecTEDIntentPolicy
#     max_history: 5
#     epochs: 100
#   - name: TEDPolicy
#     max_history: 5
#     epochs: 100
#     constrain_similarities: true

language: en
pipeline:
- name: HFTransformersNLP
model_weights: "bert-base-uncased"
model_name: "bert"
- name: LanguageModelTokenizer
- name: LanguageModelFeaturizer
- name: DIETClassifier
epochs: 100

policies:
- name: RulePolicy
  core_fallback_threshold: 0.3
  core_fallback_action_name: "action_default_fallback"
  enable_fallback_prediction: True
- max_history: 6
  name: AugmentedMemoizationPolicy
- name: TEDPolicy
  max_history: 10
  epochs: 20
  batch_size:
  - 32
  - 64
